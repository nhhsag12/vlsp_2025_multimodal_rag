{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-31T14:05:09.771712Z",
     "start_time": "2025-07-31T14:05:03.974695Z"
    }
   },
   "source": [
    "import json\n",
    "import torch\n",
    "import faiss\n",
    "\n",
    "from src.multimodal_retriever.retriever import Retriever\n",
    "from src.utils.utils import load_model\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spacetop/Hoang/vlsp_2025_multimodal_rag/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T14:05:25.413956Z",
     "start_time": "2025-07-31T14:05:18.326213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Init the model\n",
    "retriever = Retriever()"
   ],
   "id": "20c6b24f46f66ffc",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T14:05:33.504172Z",
     "start_time": "2025-07-31T14:05:32.950571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the model from the checkpoint\n",
    "model_path = \"../../trained_model/trained_model_20250731-223737/model_20250731-225721.pt\"\n",
    "retriever = load_model(retriever, model_path)"
   ],
   "id": "13485c916922dc27",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T14:05:34.709586Z",
     "start_time": "2025-07-31T14:05:34.695825Z"
    }
   },
   "cell_type": "code",
   "source": "retriever.parameters()",
   "id": "f191d1873a972e3d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7fdd30122960>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T14:05:38.541017Z",
     "start_time": "2025-07-31T14:05:38.535289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the public test of the task 1\n",
    "public_test_1_path = \"../../data/VLSP 2025 - MLQA-TSR Data Release/public_test/vlsp_2025_public_test_task2.json\"\n",
    "with open(public_test_1_path, \"r\") as f:\n",
    "    public_test = json.load(f)"
   ],
   "id": "4c19033f3316e8fd",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T14:05:39.633302Z",
     "start_time": "2025-07-31T14:05:39.430868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the embedding of the document from databases\n",
    "document_embedding_path = \"../../data/record_id_to_document_embedding.json\"\n",
    "with open(document_embedding_path, \"r\") as f:\n",
    "    document_embeddings = json.load(f)"
   ],
   "id": "b7a2e53fab989f5a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T14:05:40.214998Z",
     "start_time": "2025-07-31T14:05:40.096232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert the embedding of the document from list into tensor\n",
    "tensor_document_embeddings = {}\n",
    "for key, values in document_embeddings.items():\n",
    "    values[\"embedding\"] = torch.tensor(values[\"embedding\"])\n",
    "    tensor_document_embeddings[key] = values"
   ],
   "id": "1f632994c631aa8b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T14:05:40.594380Z",
     "start_time": "2025-07-31T14:05:40.589141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "record_id_to_embedding = {}\n",
    "for key, values in tensor_document_embeddings.items():\n",
    "    record_id_to_embedding[key] = values[\"embedding\"]"
   ],
   "id": "32fcb1108bc91b16",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T14:05:41.119262Z",
     "start_time": "2025-07-31T14:05:41.113178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a FAISS index. The dimension must match the embeddings\n",
    "key, embedding = list(record_id_to_embedding.items())[0]\n",
    "print(embedding.shape)"
   ],
   "id": "245c068e987d2e85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create a FAISS index. The dimension must match the embeddings\n",
   "id": "e66b8e0a44ec8736"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T14:05:42.230802Z",
     "start_time": "2025-07-31T14:05:42.208503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "key, embedding = list(record_id_to_embedding.items())[0]\n",
    "print(f\"Embedding dimension: {embedding.shape}\")\n",
    "\n",
    "embedding_dim = embedding.shape[0]\n",
    "index = faiss.IndexFlatIP(embedding_dim)\n",
    "\n",
    "# Add all embeddings to the index\n",
    "embeddings_matrix = []\n",
    "record_ids = []\n",
    "for record_id, embedding in record_id_to_embedding.items():\n",
    "    embeddings_matrix.append(embedding.detach().cpu().numpy())\n",
    "    record_ids.append(record_id)\n",
    "\n",
    "embeddings_matrix = torch.stack([torch.tensor(emb) for emb in embeddings_matrix]).numpy()\n",
    "index.add(embeddings_matrix)\n",
    "\n",
    "print(f\"Index created with {index.ntotal} embeddings\")\n"
   ],
   "id": "1c58ea7c351eb7c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: torch.Size([1024])\n",
      "Index created with 395 embeddings\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load images and test the retriever\n",
   "id": "91e8780da540b7ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T14:05:43.438696Z",
     "start_time": "2025-07-31T14:05:43.423857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def test_retriever_on_public_test(retriever, public_test, index, record_ids, tensor_document_embeddings, k=5):\n",
    "    \"\"\"\n",
    "    Test the retriever model on public test data\n",
    "\n",
    "    Args:\n",
    "        retriever: The trained retriever model\n",
    "        public_test: List of test questions\n",
    "        index: FAISS index for similarity search\n",
    "        record_ids: List of record IDs corresponding to index\n",
    "        tensor_document_embeddings: Dictionary mapping record_id to document info\n",
    "        k: Number of top documents to retrieve\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    image_base_path = \"../../data/VLSP 2025 - MLQA-TSR Data Release/public_test/public_test_images/public_test_images\"\n",
    "\n",
    "    retriever.eval()\n",
    "    with torch.no_grad():\n",
    "        for test_item in public_test:\n",
    "            test_id = test_item[\"id\"]\n",
    "            image_id = test_item[\"image_id\"]\n",
    "            question = test_item[\"question\"]\n",
    "\n",
    "            # Load and process image\n",
    "            image_path = os.path.join(image_base_path, f\"{image_id}.jpg\")\n",
    "            if not os.path.exists(image_path):\n",
    "                print(f\"Warning: Image not found - {image_path}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                image = Image.open(image_path).convert('RGB')\n",
    "                image = image.resize((224, 224))\n",
    "\n",
    "                # Get multimodal embedding from retriever\n",
    "                multimodal_embedding = retriever(image, question)\n",
    "                query_embedding = multimodal_embedding.reshape(1, -1)\n",
    "\n",
    "                # Search in FAISS index\n",
    "                scores, indices = index.search(query_embedding, k)\n",
    "\n",
    "                # Get top k results\n",
    "                top_results = []\n",
    "                for i, (score, idx) in enumerate(zip(scores[0], indices[0])):\n",
    "                    record_id = record_ids[idx]\n",
    "                    document_text = tensor_document_embeddings[record_id][\"text\"]\n",
    "                    top_results.append({\n",
    "                        \"rank\": i + 1,\n",
    "                        \"record_id\": record_id,\n",
    "                        \"score\": float(score),\n",
    "                        \"text\": document_text\n",
    "                    })\n",
    "\n",
    "                results.append({\n",
    "                    \"test_id\": test_id,\n",
    "                    \"image_id\": image_id,\n",
    "                    \"question\": question,\n",
    "                    \"top_results\": top_results\n",
    "                })\n",
    "\n",
    "                print(f\"Processed {test_id}: {question[:50]}...\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {test_id}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "    return results\n"
   ],
   "id": "c0f4eeef444e629",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Run the test\n",
   "id": "8da9119028c8c6c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T14:05:49.745077Z",
     "start_time": "2025-07-31T14:05:44.863635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_results = test_retriever_on_public_test(\n",
    "    retriever,\n",
    "    public_test,\n",
    "    index,\n",
    "    record_ids,\n",
    "    tensor_document_embeddings,\n",
    "    k=5\n",
    ")\n",
    "print(f\"Completed testing on {len(test_results)} items\")\n"
   ],
   "id": "819d8645a185f2d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed public_test_51: Trong tất cả biển báo trong hình bên, hãy cho biết...\n",
      "Processed public_test_52: Các biển báo xuất hiện trong hình bên là loại biển...\n",
      "Processed public_test_53: Đây là biển báo cấm vượt. Đúng hay sai?...\n",
      "Processed public_test_54: \"Biển có viền đỏ, nền trắng, hình vẽ màu đen trong...\n",
      "Processed public_test_55: Hướng đi đến Thành phố Vinh là hướng đi thẳng, đún...\n",
      "Processed public_test_56: Tốc độ nào sau đây mà người lái xe di chuyển trên ...\n",
      "Processed public_test_57: Biển báo trong hình có ý nghĩa gì?...\n",
      "Processed public_test_58: Trên phần đường có đặt biển báo trên thì đối tượng...\n",
      "Processed public_test_59: Biển báo trong ảnh cảnh  báo điều gì?...\n",
      "Processed public_test_60: Các biển báo trong ảnh thuộc loại biển báo gì?...\n",
      "Processed public_test_61: Khi gặp biển báo trong ảnh vào ngày lẻ với biển bá...\n",
      "Processed public_test_62: Biển báo trong hình là loại biển gì?...\n",
      "Processed public_test_63: Theo các biển chỉ dẫn trên ảnh thì nút giao tại ng...\n",
      "Processed public_test_64: Biển cảnh báo trong ảnh cảnh báo điều về đoạn đườn...\n",
      "Processed public_test_65: Xe ô tô đi vào 2 làn bên phải của đoạn đường trên ...\n",
      "Processed public_test_66: Người điều khiển xe ô tô con được phép dừng đỗ xe ...\n",
      "Processed public_test_67: Người điều khiển phương tiện phải giảm tốc độ khi ...\n",
      "Processed public_test_68: Người điều khiển xe máy được rẽ phải vào đường Hồn...\n",
      "Processed public_test_69: Xe ô tô tải với tải trọng  <3,5 t chỉ được phép đi...\n",
      "Processed public_test_70: Người lái xe đi trên cao tốc đế gần đoạn đường trê...\n",
      "Processed public_test_71: Biển báo trong hình có ý nghĩa như thế nào?...\n",
      "Processed public_test_72: Hai biển báo trong hình báo hiệu gì cho người lái ...\n",
      "Processed public_test_73: Khi nhìn thấy biển báo trong hình, tài xế cần xử l...\n",
      "Processed public_test_74: Biển báo trong hình cho ta biết điều gì?...\n",
      "Processed public_test_75: Biển báo trong hình có ý nghĩa như thế nào?...\n",
      "Processed public_test_76: Các phương tiện tham gia giao thông được phép dừng...\n",
      "Processed public_test_77: Loại phương tiện nào không được tham gia lưu thông...\n",
      "Processed public_test_78: Khi nhìn thấy biển báo trên, muốn đi đến Chánh An ...\n",
      "Processed public_test_79: Nội dung của biển báo trong hình là gì?...\n",
      "Processed public_test_80: Biển báo trong hình là biển báo gì?...\n",
      "Processed public_test_81: Biển báo trên cho chúng ta biết điều gì?...\n",
      "Processed public_test_82: Xe máy được phép lưu thông với tốc độ 100 km/h trê...\n",
      "Processed public_test_83: Các phương tiện giao thông được phép dừng xe trên ...\n",
      "Processed public_test_84: Đoạn đường phía trước cấm đi ngược chiều. Đúng hay...\n",
      "Processed public_test_85: Xe máy gặp đèn đỏ có biển báo này được phép rẽ phả...\n",
      "Processed public_test_86: Khi tham gia giao thông, gặp những biển báo này, h...\n",
      "Processed public_test_87: Khi điều khiển phương tiện tham gia giao thông, tr...\n",
      "Processed public_test_88: Biển báo trong hình thường được đặt ở đâu ?...\n",
      "Processed public_test_89: Biển nào báo hiệu khoảng cách thực tế từ nơi đặt b...\n",
      "Processed public_test_90: Biển báo này cho phép chạy ngược chiều với điều ki...\n",
      "Processed public_test_91: Trong hình trên chiếc xe ô tô đã vi phạm pháp luật...\n",
      "Processed public_test_92: Khi điều khiển phương tiện giao thông gặp các biển...\n",
      "Processed public_test_93: Khi điều khiển xe máy trên tuyến đường này, biển b...\n",
      "Processed public_test_94: Xe thô sơ 3 bánh được phép lưu thông vào tuyến đườ...\n",
      "Processed public_test_95: Khi tham gia giao thông, gặp biển báo này thì ngườ...\n",
      "Processed public_test_96: Biển báo giao thông này cho biết chiều dài của xe ...\n",
      "Processed public_test_97: Biển báo này là biển báo cấm chạy ngược chiều là đ...\n",
      "Processed public_test_98: Khi tham gia giao thông, gặp biển báo này thì ngườ...\n",
      "Processed public_test_99: Đoạn đường trên cho phép ưu tiên xe máy đi ngược c...\n",
      "Processed public_test_100: Biển báo này thuộc loại biển báo nào ?...\n",
      "Completed testing on 50 items\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Display results for first few test cases\n",
   "id": "9ee240d78dcd95af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T14:05:54.167069Z",
     "start_time": "2025-07-31T14:05:54.154024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, result in enumerate(test_results[:10]):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Test ID: {result['test_id']}\")\n",
    "    print(f\"Image ID: {result['image_id']}\")\n",
    "    print(f\"Question: {result['question']}\")\n",
    "    print(f\"Top 3 Retrieved Documents:\")\n",
    "\n",
    "    for j, doc in enumerate(result['top_results'][:3]):\n",
    "        print(f\"\\n--- Rank {doc['rank']} (Score: {doc['score']:.4f}) ---\")\n",
    "        print(f\"Record ID: {doc['record_id']}\")\n",
    "        print(f\"Text: {doc['text'][:200]}...\")\n"
   ],
   "id": "5f827e6bce6d9335",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Test ID: public_test_51\n",
      "Image ID: public_test_5_6\n",
      "Question: Trong tất cả biển báo trong hình bên, hãy cho biết xe gắn máy bị cấm đi thẳng trong khoảng thời gian nào?\n",
      "Top 3 Retrieved Documents:\n",
      "\n",
      "--- Rank 1 (Score: 0.9946) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#22\n",
      "Text: Ý nghĩa sử dụng các biển báo cấm\n",
      "22.1.   tên các biển như sau:\n",
      "- Biển số P.101: Đường cấm;\n",
      "- Biển số P.102: Cấm đi ngược chiều;\n",
      "- Biển số P.103a: Cấm xe ô tô;\n",
      "- Biển số P.103(b,c): Cấm xe ô tô rẽ trái...\n",
      "\n",
      "--- Rank 2 (Score: 0.8593) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#M.1\n",
      "Text: M.1  Nhóm biển báo cấm\n",
      "Biển số P.101: Đường cấm\n",
      "\n",
      "\n",
      "Biển số P.102: Cấm đi ngược chiều\n",
      "\n",
      "\n",
      "Biển số P.103a: Cấm xe ôtô\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "| Loại đường   |   Đường cao tốc |   Đường đôi ngoài đô thị |   Đường thông thường ...\n",
      "\n",
      "--- Rank 3 (Score: 0.8451) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#32\n",
      "Text: Ý nghĩa sử dụng các biển hiệu lệnh\n",
      "32.1. Biển hiệu lệnh có mã R và R.E với tên các biển như sau:\n",
      "- Biển số R.122: Dừng lại;\n",
      "- Biển số R.301(a,b,c,d,e,f,g,h): Hướng đi phải theo;\n",
      "- Biển số R.302(a,b,c)...\n",
      "\n",
      "==================================================\n",
      "Test ID: public_test_52\n",
      "Image ID: public_test_5_12\n",
      "Question: Các biển báo xuất hiện trong hình bên là loại biển báo gì?\n",
      "Top 3 Retrieved Documents:\n",
      "\n",
      "--- Rank 1 (Score: 0.9946) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#22\n",
      "Text: Ý nghĩa sử dụng các biển báo cấm\n",
      "22.1.   tên các biển như sau:\n",
      "- Biển số P.101: Đường cấm;\n",
      "- Biển số P.102: Cấm đi ngược chiều;\n",
      "- Biển số P.103a: Cấm xe ô tô;\n",
      "- Biển số P.103(b,c): Cấm xe ô tô rẽ trái...\n",
      "\n",
      "--- Rank 2 (Score: 0.8594) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#M.1\n",
      "Text: M.1  Nhóm biển báo cấm\n",
      "Biển số P.101: Đường cấm\n",
      "\n",
      "\n",
      "Biển số P.102: Cấm đi ngược chiều\n",
      "\n",
      "\n",
      "Biển số P.103a: Cấm xe ôtô\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "| Loại đường   |   Đường cao tốc |   Đường đôi ngoài đô thị |   Đường thông thường ...\n",
      "\n",
      "--- Rank 3 (Score: 0.8451) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#32\n",
      "Text: Ý nghĩa sử dụng các biển hiệu lệnh\n",
      "32.1. Biển hiệu lệnh có mã R và R.E với tên các biển như sau:\n",
      "- Biển số R.122: Dừng lại;\n",
      "- Biển số R.301(a,b,c,d,e,f,g,h): Hướng đi phải theo;\n",
      "- Biển số R.302(a,b,c)...\n",
      "\n",
      "==================================================\n",
      "Test ID: public_test_53\n",
      "Image ID: public_test_5_11\n",
      "Question: Đây là biển báo cấm vượt. Đúng hay sai?\n",
      "Top 3 Retrieved Documents:\n",
      "\n",
      "--- Rank 1 (Score: 0.9946) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#22\n",
      "Text: Ý nghĩa sử dụng các biển báo cấm\n",
      "22.1.   tên các biển như sau:\n",
      "- Biển số P.101: Đường cấm;\n",
      "- Biển số P.102: Cấm đi ngược chiều;\n",
      "- Biển số P.103a: Cấm xe ô tô;\n",
      "- Biển số P.103(b,c): Cấm xe ô tô rẽ trái...\n",
      "\n",
      "--- Rank 2 (Score: 0.8594) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#M.1\n",
      "Text: M.1  Nhóm biển báo cấm\n",
      "Biển số P.101: Đường cấm\n",
      "\n",
      "\n",
      "Biển số P.102: Cấm đi ngược chiều\n",
      "\n",
      "\n",
      "Biển số P.103a: Cấm xe ôtô\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "| Loại đường   |   Đường cao tốc |   Đường đôi ngoài đô thị |   Đường thông thường ...\n",
      "\n",
      "--- Rank 3 (Score: 0.8451) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#32\n",
      "Text: Ý nghĩa sử dụng các biển hiệu lệnh\n",
      "32.1. Biển hiệu lệnh có mã R và R.E với tên các biển như sau:\n",
      "- Biển số R.122: Dừng lại;\n",
      "- Biển số R.301(a,b,c,d,e,f,g,h): Hướng đi phải theo;\n",
      "- Biển số R.302(a,b,c)...\n",
      "\n",
      "==================================================\n",
      "Test ID: public_test_54\n",
      "Image ID: public_test_5_7\n",
      "Question: \"Biển có viền đỏ, nền trắng, hình vẽ màu đen trong hình bên là biển báo cấm rẽ phải\". Đúng hay sai?\n",
      "Top 3 Retrieved Documents:\n",
      "\n",
      "--- Rank 1 (Score: 0.9946) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#22\n",
      "Text: Ý nghĩa sử dụng các biển báo cấm\n",
      "22.1.   tên các biển như sau:\n",
      "- Biển số P.101: Đường cấm;\n",
      "- Biển số P.102: Cấm đi ngược chiều;\n",
      "- Biển số P.103a: Cấm xe ô tô;\n",
      "- Biển số P.103(b,c): Cấm xe ô tô rẽ trái...\n",
      "\n",
      "--- Rank 2 (Score: 0.8594) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#M.1\n",
      "Text: M.1  Nhóm biển báo cấm\n",
      "Biển số P.101: Đường cấm\n",
      "\n",
      "\n",
      "Biển số P.102: Cấm đi ngược chiều\n",
      "\n",
      "\n",
      "Biển số P.103a: Cấm xe ôtô\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "| Loại đường   |   Đường cao tốc |   Đường đôi ngoài đô thị |   Đường thông thường ...\n",
      "\n",
      "--- Rank 3 (Score: 0.8451) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#32\n",
      "Text: Ý nghĩa sử dụng các biển hiệu lệnh\n",
      "32.1. Biển hiệu lệnh có mã R và R.E với tên các biển như sau:\n",
      "- Biển số R.122: Dừng lại;\n",
      "- Biển số R.301(a,b,c,d,e,f,g,h): Hướng đi phải theo;\n",
      "- Biển số R.302(a,b,c)...\n",
      "\n",
      "==================================================\n",
      "Test ID: public_test_55\n",
      "Image ID: public_test_5_5\n",
      "Question: Hướng đi đến Thành phố Vinh là hướng đi thẳng, đúng hay sai?\n",
      "Top 3 Retrieved Documents:\n",
      "\n",
      "--- Rank 1 (Score: 0.9946) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#22\n",
      "Text: Ý nghĩa sử dụng các biển báo cấm\n",
      "22.1.   tên các biển như sau:\n",
      "- Biển số P.101: Đường cấm;\n",
      "- Biển số P.102: Cấm đi ngược chiều;\n",
      "- Biển số P.103a: Cấm xe ô tô;\n",
      "- Biển số P.103(b,c): Cấm xe ô tô rẽ trái...\n",
      "\n",
      "--- Rank 2 (Score: 0.8593) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#M.1\n",
      "Text: M.1  Nhóm biển báo cấm\n",
      "Biển số P.101: Đường cấm\n",
      "\n",
      "\n",
      "Biển số P.102: Cấm đi ngược chiều\n",
      "\n",
      "\n",
      "Biển số P.103a: Cấm xe ôtô\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "| Loại đường   |   Đường cao tốc |   Đường đôi ngoài đô thị |   Đường thông thường ...\n",
      "\n",
      "--- Rank 3 (Score: 0.8451) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#32\n",
      "Text: Ý nghĩa sử dụng các biển hiệu lệnh\n",
      "32.1. Biển hiệu lệnh có mã R và R.E với tên các biển như sau:\n",
      "- Biển số R.122: Dừng lại;\n",
      "- Biển số R.301(a,b,c,d,e,f,g,h): Hướng đi phải theo;\n",
      "- Biển số R.302(a,b,c)...\n",
      "\n",
      "==================================================\n",
      "Test ID: public_test_56\n",
      "Image ID: public_test_6_12\n",
      "Question: Tốc độ nào sau đây mà người lái xe di chuyển trên đoạn đường trong ảnh là không phạp luật?\n",
      "Top 3 Retrieved Documents:\n",
      "\n",
      "--- Rank 1 (Score: 0.9946) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#22\n",
      "Text: Ý nghĩa sử dụng các biển báo cấm\n",
      "22.1.   tên các biển như sau:\n",
      "- Biển số P.101: Đường cấm;\n",
      "- Biển số P.102: Cấm đi ngược chiều;\n",
      "- Biển số P.103a: Cấm xe ô tô;\n",
      "- Biển số P.103(b,c): Cấm xe ô tô rẽ trái...\n",
      "\n",
      "--- Rank 2 (Score: 0.8593) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#M.1\n",
      "Text: M.1  Nhóm biển báo cấm\n",
      "Biển số P.101: Đường cấm\n",
      "\n",
      "\n",
      "Biển số P.102: Cấm đi ngược chiều\n",
      "\n",
      "\n",
      "Biển số P.103a: Cấm xe ôtô\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "| Loại đường   |   Đường cao tốc |   Đường đôi ngoài đô thị |   Đường thông thường ...\n",
      "\n",
      "--- Rank 3 (Score: 0.8451) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#32\n",
      "Text: Ý nghĩa sử dụng các biển hiệu lệnh\n",
      "32.1. Biển hiệu lệnh có mã R và R.E với tên các biển như sau:\n",
      "- Biển số R.122: Dừng lại;\n",
      "- Biển số R.301(a,b,c,d,e,f,g,h): Hướng đi phải theo;\n",
      "- Biển số R.302(a,b,c)...\n",
      "\n",
      "==================================================\n",
      "Test ID: public_test_57\n",
      "Image ID: public_test_6_9\n",
      "Question: Biển báo trong hình có ý nghĩa gì?\n",
      "Top 3 Retrieved Documents:\n",
      "\n",
      "--- Rank 1 (Score: 0.9946) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#22\n",
      "Text: Ý nghĩa sử dụng các biển báo cấm\n",
      "22.1.   tên các biển như sau:\n",
      "- Biển số P.101: Đường cấm;\n",
      "- Biển số P.102: Cấm đi ngược chiều;\n",
      "- Biển số P.103a: Cấm xe ô tô;\n",
      "- Biển số P.103(b,c): Cấm xe ô tô rẽ trái...\n",
      "\n",
      "--- Rank 2 (Score: 0.8594) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#M.1\n",
      "Text: M.1  Nhóm biển báo cấm\n",
      "Biển số P.101: Đường cấm\n",
      "\n",
      "\n",
      "Biển số P.102: Cấm đi ngược chiều\n",
      "\n",
      "\n",
      "Biển số P.103a: Cấm xe ôtô\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "| Loại đường   |   Đường cao tốc |   Đường đôi ngoài đô thị |   Đường thông thường ...\n",
      "\n",
      "--- Rank 3 (Score: 0.8451) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#32\n",
      "Text: Ý nghĩa sử dụng các biển hiệu lệnh\n",
      "32.1. Biển hiệu lệnh có mã R và R.E với tên các biển như sau:\n",
      "- Biển số R.122: Dừng lại;\n",
      "- Biển số R.301(a,b,c,d,e,f,g,h): Hướng đi phải theo;\n",
      "- Biển số R.302(a,b,c)...\n",
      "\n",
      "==================================================\n",
      "Test ID: public_test_58\n",
      "Image ID: public_test_6_6\n",
      "Question: Trên phần đường có đặt biển báo trên thì đối tượng tham gia giao thông nào sau đây không được phép đi lại?\n",
      "Top 3 Retrieved Documents:\n",
      "\n",
      "--- Rank 1 (Score: 0.9946) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#22\n",
      "Text: Ý nghĩa sử dụng các biển báo cấm\n",
      "22.1.   tên các biển như sau:\n",
      "- Biển số P.101: Đường cấm;\n",
      "- Biển số P.102: Cấm đi ngược chiều;\n",
      "- Biển số P.103a: Cấm xe ô tô;\n",
      "- Biển số P.103(b,c): Cấm xe ô tô rẽ trái...\n",
      "\n",
      "--- Rank 2 (Score: 0.8594) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#M.1\n",
      "Text: M.1  Nhóm biển báo cấm\n",
      "Biển số P.101: Đường cấm\n",
      "\n",
      "\n",
      "Biển số P.102: Cấm đi ngược chiều\n",
      "\n",
      "\n",
      "Biển số P.103a: Cấm xe ôtô\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "| Loại đường   |   Đường cao tốc |   Đường đôi ngoài đô thị |   Đường thông thường ...\n",
      "\n",
      "--- Rank 3 (Score: 0.8451) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#32\n",
      "Text: Ý nghĩa sử dụng các biển hiệu lệnh\n",
      "32.1. Biển hiệu lệnh có mã R và R.E với tên các biển như sau:\n",
      "- Biển số R.122: Dừng lại;\n",
      "- Biển số R.301(a,b,c,d,e,f,g,h): Hướng đi phải theo;\n",
      "- Biển số R.302(a,b,c)...\n",
      "\n",
      "==================================================\n",
      "Test ID: public_test_59\n",
      "Image ID: public_test_6_15\n",
      "Question: Biển báo trong ảnh cảnh  báo điều gì?\n",
      "Top 3 Retrieved Documents:\n",
      "\n",
      "--- Rank 1 (Score: 0.9946) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#22\n",
      "Text: Ý nghĩa sử dụng các biển báo cấm\n",
      "22.1.   tên các biển như sau:\n",
      "- Biển số P.101: Đường cấm;\n",
      "- Biển số P.102: Cấm đi ngược chiều;\n",
      "- Biển số P.103a: Cấm xe ô tô;\n",
      "- Biển số P.103(b,c): Cấm xe ô tô rẽ trái...\n",
      "\n",
      "--- Rank 2 (Score: 0.8594) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#M.1\n",
      "Text: M.1  Nhóm biển báo cấm\n",
      "Biển số P.101: Đường cấm\n",
      "\n",
      "\n",
      "Biển số P.102: Cấm đi ngược chiều\n",
      "\n",
      "\n",
      "Biển số P.103a: Cấm xe ôtô\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "| Loại đường   |   Đường cao tốc |   Đường đôi ngoài đô thị |   Đường thông thường ...\n",
      "\n",
      "--- Rank 3 (Score: 0.8451) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#32\n",
      "Text: Ý nghĩa sử dụng các biển hiệu lệnh\n",
      "32.1. Biển hiệu lệnh có mã R và R.E với tên các biển như sau:\n",
      "- Biển số R.122: Dừng lại;\n",
      "- Biển số R.301(a,b,c,d,e,f,g,h): Hướng đi phải theo;\n",
      "- Biển số R.302(a,b,c)...\n",
      "\n",
      "==================================================\n",
      "Test ID: public_test_60\n",
      "Image ID: public_test_6_7\n",
      "Question: Các biển báo trong ảnh thuộc loại biển báo gì?\n",
      "Top 3 Retrieved Documents:\n",
      "\n",
      "--- Rank 1 (Score: 0.9946) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#22\n",
      "Text: Ý nghĩa sử dụng các biển báo cấm\n",
      "22.1.   tên các biển như sau:\n",
      "- Biển số P.101: Đường cấm;\n",
      "- Biển số P.102: Cấm đi ngược chiều;\n",
      "- Biển số P.103a: Cấm xe ô tô;\n",
      "- Biển số P.103(b,c): Cấm xe ô tô rẽ trái...\n",
      "\n",
      "--- Rank 2 (Score: 0.8594) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#M.1\n",
      "Text: M.1  Nhóm biển báo cấm\n",
      "Biển số P.101: Đường cấm\n",
      "\n",
      "\n",
      "Biển số P.102: Cấm đi ngược chiều\n",
      "\n",
      "\n",
      "Biển số P.103a: Cấm xe ôtô\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "| Loại đường   |   Đường cao tốc |   Đường đôi ngoài đô thị |   Đường thông thường ...\n",
      "\n",
      "--- Rank 3 (Score: 0.8451) ---\n",
      "Record ID: QCVN 41:2024/BGTVT#32\n",
      "Text: Ý nghĩa sử dụng các biển hiệu lệnh\n",
      "32.1. Biển hiệu lệnh có mã R và R.E với tên các biển như sau:\n",
      "- Biển số R.122: Dừng lại;\n",
      "- Biển số R.301(a,b,c,d,e,f,g,h): Hướng đi phải theo;\n",
      "- Biển số R.302(a,b,c)...\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Filter results by similarity threshold",
   "id": "a509b839c350c14e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T14:06:00.112119Z",
     "start_time": "2025-07-31T14:06:00.103491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def filter_results_by_threshold(test_results, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Filter retrieved documents to only keep those with similarity score > threshold\n",
    "\n",
    "    Args:\n",
    "        test_results: List of test results from retriever\n",
    "        threshold: Minimum similarity score to keep (default: 0.8)\n",
    "\n",
    "    Returns:\n",
    "        Filtered test results with high-confidence retrievals only\n",
    "    \"\"\"\n",
    "    filtered_results = []\n",
    "\n",
    "    for result in test_results:\n",
    "        # Filter top_results to only include scores > threshold\n",
    "        high_confidence_results = [\n",
    "            doc for doc in result['top_results']\n",
    "            if doc['score'] > threshold\n",
    "        ]\n",
    "\n",
    "        # Update ranks after filtering\n",
    "        for i, doc in enumerate(high_confidence_results):\n",
    "            doc['rank'] = i + 1\n",
    "\n",
    "        # Create filtered result\n",
    "        filtered_result = {\n",
    "            \"test_id\": result['test_id'],\n",
    "            \"image_id\": result['image_id'],\n",
    "            \"question\": result['question'],\n",
    "            \"top_results\": high_confidence_results,\n",
    "            \"original_count\": len(result['top_results']),\n",
    "            \"filtered_count\": len(high_confidence_results)\n",
    "        }\n",
    "\n",
    "        filtered_results.append(filtered_result)\n",
    "\n",
    "    return filtered_results"
   ],
   "id": "97a3b405e88e9c85",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Apply filtering with threshold 0.8",
   "id": "ffbe75121ffbaa59"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T14:06:10.334967Z",
     "start_time": "2025-07-31T14:06:10.332032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "similarity_threshold = 0.8\n",
    "filtered_test_results = filter_results_by_threshold(test_results, similarity_threshold)\n",
    "\n",
    "print(f\"Filtering results with similarity threshold > {similarity_threshold}\")\n",
    "print(f\"Total test cases: {len(filtered_test_results)}\")"
   ],
   "id": "f11aa52ee623b9a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering results with similarity threshold > 0.8\n",
      "Total test cases: 50\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T14:06:11.016599Z",
     "start_time": "2025-07-31T14:06:11.013475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for test_result in filtered_test_results:\n",
    "    top_results = test_result[\"top_results\"]\n",
    "    test_result[\"relevant_articles\"] = []\n",
    "    for top_result in top_results:\n",
    "        law_article_id = top_result[\"record_id\"].strip().split(\"#\")\n",
    "        law_id = law_article_id[0]\n",
    "        article_id = law_article_id[1]\n",
    "        test_result[\"relevant_articles\"].append({\n",
    "            \"law_id\": law_id,\n",
    "            \"article_id\": article_id,\n",
    "        })"
   ],
   "id": "6cca98c9c1a3c243",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T14:06:12.375064Z",
     "start_time": "2025-07-31T14:06:12.369878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_law_and_article_id(record_id):\n",
    "    \"\"\"\n",
    "    Extract law_id and article_id from record_id\n",
    "    Expected format: \"law_id#article_id\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parts = record_id.split('#')\n",
    "        if len(parts) == 2:\n",
    "            return parts[0], parts[1]\n",
    "        else:\n",
    "            return None, None\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "def calculate_f2_score_per_sample(retrieved_record_ids, relevant_articles):\n",
    "    \"\"\"\n",
    "    Calculate F2 score for a single test sample\n",
    "\n",
    "    Args:\n",
    "        retrieved_record_ids: List of record IDs retrieved by the model\n",
    "        relevant_articles: List of relevant articles from ground truth\n",
    "                          Each item has structure: {\"law_id\": \"...\", \"article_id\": \"...\"}\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with precision, recall, f2_score\n",
    "    \"\"\"\n",
    "    # Convert relevant articles to set of (law_id, article_id) tuples\n",
    "    relevant_set = set()\n",
    "    for article in relevant_articles:\n",
    "        relevant_set.add((article[\"law_id\"], article[\"article_id\"]))\n",
    "\n",
    "    # Convert retrieved record IDs to set of (law_id, article_id) tuples\n",
    "    retrieved_set = set()\n",
    "    for record_id in retrieved_record_ids:\n",
    "        law_id, article_id = extract_law_and_article_id(record_id)\n",
    "        if law_id and article_id:\n",
    "            retrieved_set.add((law_id, article_id))\n",
    "\n",
    "    # Calculate metrics\n",
    "    num_retrieved = len(retrieved_set)\n",
    "    num_relevant = len(relevant_set)\n",
    "    num_correct = len(retrieved_set.intersection(relevant_set))\n",
    "\n",
    "    # Calculate precision and recall\n",
    "    precision = num_correct / num_retrieved if num_retrieved > 0 else 0.0\n",
    "    recall = num_correct / num_relevant if num_relevant > 0 else 0.0\n",
    "\n",
    "    # Calculate F2 score\n",
    "    if precision + recall > 0:\n",
    "        f2_score = (5 * precision * recall) / (4 * precision + recall)\n",
    "    else:\n",
    "        f2_score = 0.0\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f2_score\": f2_score,\n",
    "        \"num_retrieved\": num_retrieved,\n",
    "        \"num_relevant\": num_relevant,\n",
    "        \"num_correct\": num_correct,\n",
    "        \"retrieved_articles\": retrieved_set,\n",
    "        \"relevant_articles\": relevant_set,\n",
    "        \"correct_articles\": retrieved_set.intersection(relevant_set)\n",
    "    }\n"
   ],
   "id": "7a7c3c570f1bbfb",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T14:06:13.036492Z",
     "start_time": "2025-07-31T14:06:13.026008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_overall_f2_score(filtered_test_results, public_test):\n",
    "    \"\"\"\n",
    "    Calculate F2 score for all test samples\n",
    "\n",
    "    Args:\n",
    "        filtered_test_results: Results from the retriever model (filtered)\n",
    "        public_test: Ground truth test data\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with overall metrics and per-sample details\n",
    "    \"\"\"\n",
    "    # Create mapping from test_id to public_test item\n",
    "    public_test_dict = {item[\"id\"]: item for item in public_test}\n",
    "\n",
    "    per_sample_metrics = []\n",
    "    total_precision = 0.0\n",
    "    total_recall = 0.0\n",
    "    total_f2 = 0.0\n",
    "    samples_processed = 0\n",
    "\n",
    "    for result in filtered_test_results:\n",
    "        test_id = result[\"test_id\"]\n",
    "\n",
    "        # Find corresponding ground truth\n",
    "        if test_id not in public_test_dict:\n",
    "            print(f\"Warning: Test ID {test_id} not found in public test data\")\n",
    "            continue\n",
    "\n",
    "        ground_truth = public_test_dict[test_id]\n",
    "        relevant_articles = ground_truth.get(\"relevant_articles\", [])\n",
    "\n",
    "        # Extract retrieved record IDs\n",
    "        retrieved_record_ids = [doc[\"record_id\"] for doc in result[\"top_results\"]]\n",
    "\n",
    "        # Calculate metrics for this sample\n",
    "        sample_metrics = calculate_f2_score_per_sample(retrieved_record_ids, relevant_articles)\n",
    "        sample_metrics[\"test_id\"] = test_id\n",
    "        sample_metrics[\"question\"] = result[\"question\"]\n",
    "\n",
    "        per_sample_metrics.append(sample_metrics)\n",
    "\n",
    "        # Accumulate for overall metrics\n",
    "        total_precision += sample_metrics[\"precision\"]\n",
    "        total_recall += sample_metrics[\"recall\"]\n",
    "        total_f2 += sample_metrics[\"f2_score\"]\n",
    "        samples_processed += 1\n",
    "\n",
    "    # Calculate averages\n",
    "    avg_precision = total_precision / samples_processed if samples_processed > 0 else 0.0\n",
    "    avg_recall = total_recall / samples_processed if samples_processed > 0 else 0.0\n",
    "    avg_f2 = total_f2 / samples_processed if samples_processed > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        \"overall_metrics\": {\n",
    "            \"avg_precision\": avg_precision,\n",
    "            \"avg_recall\": avg_recall,\n",
    "            \"avg_f2_score\": avg_f2,\n",
    "            \"samples_processed\": samples_processed,\n",
    "            \"total_samples\": len(filtered_test_results)\n",
    "        },\n",
    "        \"per_sample_metrics\": per_sample_metrics\n",
    "    }\n"
   ],
   "id": "4442dd7431bb82c1",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T14:06:13.541998Z",
     "start_time": "2025-07-31T14:06:13.531246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate F2 scores\n",
    "print(\"Calculating F2 scores...\")\n",
    "f2_results = calculate_overall_f2_score(filtered_test_results, public_test)\n",
    "\n",
    "# Display overall results\n",
    "overall = f2_results[\"overall_metrics\"]\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"F2 SCORE EVALUATION RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Samples processed: {overall['samples_processed']}/{overall['total_samples']}\")\n",
    "print(f\"Average Precision: {overall['avg_precision']:.4f}\")\n",
    "print(f\"Average Recall: {overall['avg_recall']:.4f}\")\n",
    "print(f\"Average F2 Score: {overall['avg_f2_score']:.4f}\")"
   ],
   "id": "1d526c7df72430e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating F2 scores...\n",
      "\n",
      "============================================================\n",
      "F2 SCORE EVALUATION RESULTS\n",
      "============================================================\n",
      "Samples processed: 50/50\n",
      "Average Precision: 0.1480\n",
      "Average Recall: 0.3417\n",
      "Average F2 Score: 0.2682\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "938f548b3179f006"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Analyze filtering impact",
   "id": "62d51d52e1780172"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T08:47:40.148507Z",
     "start_time": "2025-07-31T08:47:40.131563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def analyze_filtering_impact(filtered_results, threshold):\n",
    "    \"\"\"Analyze the impact of filtering on retrieval results\"\"\"\n",
    "\n",
    "    total_cases = len(filtered_results)\n",
    "    cases_with_results = sum(1 for r in filtered_results if len(r['top_results']) > 0)\n",
    "    cases_without_results = total_cases - cases_with_results\n",
    "\n",
    "    # Calculate total documents before/after filtering\n",
    "    total_original = sum(r['original_count'] for r in filtered_results)\n",
    "    total_filtered = sum(r['filtered_count'] for r in filtered_results)\n",
    "\n",
    "    # Calculate average filtered count per case\n",
    "    avg_filtered_per_case = total_filtered / total_cases if total_cases > 0 else 0\n",
    "\n",
    "    # Get statistics for cases with results\n",
    "    if cases_with_results > 0:\n",
    "        scores_above_threshold = []\n",
    "        for result in filtered_results:\n",
    "            for doc in result['top_results']:\n",
    "                scores_above_threshold.append(doc['score'])\n",
    "\n",
    "        avg_high_confidence_score = np.mean(scores_above_threshold) if scores_above_threshold else 0\n",
    "        min_score = min(scores_above_threshold) if scores_above_threshold else 0\n",
    "        max_score = max(scores_above_threshold) if scores_above_threshold else 0\n",
    "    else:\n",
    "        avg_high_confidence_score = 0\n",
    "        min_score = 0\n",
    "        max_score = 0\n",
    "\n",
    "    print(f\"\\n{'=' * 50}\")\n",
    "    print(f\"FILTERING ANALYSIS (Threshold: {threshold})\")\n",
    "    print(f\"{'=' * 50}\")\n",
    "    print(f\"Total test cases: {total_cases}\")\n",
    "    print(f\"Cases with high-confidence results: {cases_with_results} ({cases_with_results / total_cases * 100:.1f}%)\")\n",
    "    print(\n",
    "        f\"Cases without high-confidence results: {cases_without_results} ({cases_without_results / total_cases * 100:.1f}%)\")\n",
    "    print(f\"Total documents before filtering: {total_original}\")\n",
    "    print(f\"Total documents after filtering: {total_filtered}\")\n",
    "    print(f\"Filtering retention rate: {total_filtered / total_original * 100:.1f}%\" if total_original > 0 else \"N/A\")\n",
    "    print(f\"Average high-confidence documents per case: {avg_filtered_per_case:.2f}\")\n",
    "\n",
    "    if cases_with_results > 0:\n",
    "        print(f\"Average score of high-confidence results: {avg_high_confidence_score:.4f}\")\n",
    "        print(f\"Score range: {min_score:.4f} - {max_score:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"total_cases\": total_cases,\n",
    "        \"cases_with_results\": cases_with_results,\n",
    "        \"cases_without_results\": cases_without_results,\n",
    "        \"retention_rate\": total_filtered / total_original if total_original > 0 else 0,\n",
    "        \"avg_filtered_per_case\": avg_filtered_per_case,\n",
    "        \"avg_high_confidence_score\": avg_high_confidence_score\n",
    "    }\n",
    "\n",
    "\n",
    "filtering_analysis = analyze_filtering_impact(filtered_test_results, similarity_threshold)"
   ],
   "id": "f05758a2d912e78d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "FILTERING ANALYSIS (Threshold: 0.9)\n",
      "==================================================\n",
      "Total test cases: 50\n",
      "Cases with high-confidence results: 42 (84.0%)\n",
      "Cases without high-confidence results: 8 (16.0%)\n",
      "Total documents before filtering: 250\n",
      "Total documents after filtering: 49\n",
      "Filtering retention rate: 19.6%\n",
      "Average high-confidence documents per case: 0.98\n",
      "Average score of high-confidence results: 0.9486\n",
      "Score range: 0.9037 - 0.9936\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T15:41:22.057445Z",
     "start_time": "2025-07-30T15:41:22.053873Z"
    }
   },
   "cell_type": "markdown",
   "source": "# Display filtered results for cases with high-confidence retrievals",
   "id": "1d28a8423a49ab00"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T15:47:21.171391Z",
     "start_time": "2025-07-30T15:47:21.156996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"HIGH-CONFIDENCE RETRIEVAL RESULTS\")\n",
    "print(f\"{'=' * 60}\")\n",
    "\n",
    "high_confidence_cases = [r for r in filtered_test_results if len(r['top_results']) > 0]\n",
    "\n",
    "for i, result in enumerate(high_confidence_cases[:5]):  # Show first 5 cases with results\n",
    "    print(f\"\\n{'-' * 40}\")\n",
    "    print(f\"Test ID: {result['test_id']}\")\n",
    "    print(f\"Question: {result['question']}\")\n",
    "    print(f\"High-confidence documents found: {result['filtered_count']}\")\n",
    "\n",
    "    for doc in result['top_results'][:3]:  # Show top 3 high-confidence results\n",
    "        print(f\"\\n  Rank {doc['rank']} (Score: {doc['score']:.4f})\")\n",
    "        print(f\"  Record ID: {doc['record_id']}\")\n",
    "        print(f\"  Text: {doc['text'][:200]}...\")\n",
    "\n",
    "# Display cases without high-confidence results\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"CASES WITHOUT HIGH-CONFIDENCE RESULTS\")\n",
    "print(f\"{'=' * 60}\")\n",
    "\n",
    "no_confidence_cases = [r for r in filtered_test_results if len(r['top_results']) == 0]\n",
    "\n",
    "for i, result in enumerate(no_confidence_cases[:5]):  # Show first 5 cases without results\n",
    "    print(f\"\\n{'-' * 40}\")\n",
    "    print(f\"Test ID: {result['test_id']}\")\n",
    "    print(f\"Question: {result['question']}\")\n",
    "    print(f\"Original results: {result['original_count']}, After filtering: {result['filtered_count']}\")\n"
   ],
   "id": "10b591eb19a05fae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "HIGH-CONFIDENCE RETRIEVAL RESULTS\n",
      "============================================================\n",
      "\n",
      "----------------------------------------\n",
      "Test ID: public_test_51\n",
      "Question: Trong tất cả biển báo trong hình bên, hãy cho biết xe gắn máy bị cấm đi thẳng trong khoảng thời gian nào?\n",
      "High-confidence documents found: 5\n",
      "\n",
      "  Rank 1 (Score: 0.9669)\n",
      "  Record ID: QCVN 41:2024/BGTVT#22\n",
      "  Text: Ý nghĩa sử dụng các biển báo cấm\n",
      "22.1.   tên các biển như sau:\n",
      "- Biển số P.101: Đường cấm;\n",
      "- Biển số P.102: Cấm đi ngược chiều;\n",
      "- Biển số P.103a: Cấm xe ô tô;\n",
      "- Biển số P.103(b,c): Cấm xe ô tô rẽ trái...\n",
      "\n",
      "  Rank 2 (Score: 0.8715)\n",
      "  Record ID: QCVN 41:2024/BGTVT#32\n",
      "  Text: Ý nghĩa sử dụng các biển hiệu lệnh\n",
      "32.1. Biển hiệu lệnh có mã R và R.E với tên các biển như sau:\n",
      "- Biển số R.122: Dừng lại;\n",
      "- Biển số R.301(a,b,c,d,e,f,g,h): Hướng đi phải theo;\n",
      "- Biển số R.302(a,b,c)...\n",
      "\n",
      "  Rank 3 (Score: 0.8403)\n",
      "  Record ID: QCVN 41:2024/BGTVT#36\n",
      "  Text: Ý nghĩa sử dụng các biển chỉ dẫn\n",
      "36.1. Biển chỉ dẫn trên các đường ô tô không phải là đường cao tốc có mã “I” với tên các biển như sau:\n",
      "- Biển số I.401: Bắt đầu đường ưu tiên;\n",
      "- Biển số I.402: Hết đoạ...\n",
      "\n",
      "----------------------------------------\n",
      "Test ID: public_test_52\n",
      "Question: Các biển báo xuất hiện trong hình bên là loại biển báo gì?\n",
      "High-confidence documents found: 5\n",
      "\n",
      "  Rank 1 (Score: 0.9347)\n",
      "  Record ID: QCVN 41:2024/BGTVT#22\n",
      "  Text: Ý nghĩa sử dụng các biển báo cấm\n",
      "22.1.   tên các biển như sau:\n",
      "- Biển số P.101: Đường cấm;\n",
      "- Biển số P.102: Cấm đi ngược chiều;\n",
      "- Biển số P.103a: Cấm xe ô tô;\n",
      "- Biển số P.103(b,c): Cấm xe ô tô rẽ trái...\n",
      "\n",
      "  Rank 2 (Score: 0.9076)\n",
      "  Record ID: QCVN 41:2024/BGTVT#32\n",
      "  Text: Ý nghĩa sử dụng các biển hiệu lệnh\n",
      "32.1. Biển hiệu lệnh có mã R và R.E với tên các biển như sau:\n",
      "- Biển số R.122: Dừng lại;\n",
      "- Biển số R.301(a,b,c,d,e,f,g,h): Hướng đi phải theo;\n",
      "- Biển số R.302(a,b,c)...\n",
      "\n",
      "  Rank 3 (Score: 0.8764)\n",
      "  Record ID: QCVN 41:2024/BGTVT#36\n",
      "  Text: Ý nghĩa sử dụng các biển chỉ dẫn\n",
      "36.1. Biển chỉ dẫn trên các đường ô tô không phải là đường cao tốc có mã “I” với tên các biển như sau:\n",
      "- Biển số I.401: Bắt đầu đường ưu tiên;\n",
      "- Biển số I.402: Hết đoạ...\n",
      "\n",
      "----------------------------------------\n",
      "Test ID: public_test_53\n",
      "Question: Đây là biển báo cấm vượt. Đúng hay sai?\n",
      "High-confidence documents found: 5\n",
      "\n",
      "  Rank 1 (Score: 0.9802)\n",
      "  Record ID: QCVN 41:2024/BGTVT#22\n",
      "  Text: Ý nghĩa sử dụng các biển báo cấm\n",
      "22.1.   tên các biển như sau:\n",
      "- Biển số P.101: Đường cấm;\n",
      "- Biển số P.102: Cấm đi ngược chiều;\n",
      "- Biển số P.103a: Cấm xe ô tô;\n",
      "- Biển số P.103(b,c): Cấm xe ô tô rẽ trái...\n",
      "\n",
      "  Rank 2 (Score: 0.8415)\n",
      "  Record ID: QCVN 41:2024/BGTVT#B.2\n",
      "  Text: B.2 Biển số P.102 “Cấm đi ngược chiều”\n",
      "a) Để báo đường cấm các loại xe (cơ giới và thô sơ) đi vào theo chiều đặt biển, trừ các xe được ưu tiên theo quy định, đặt biển số P.102 “Cấm đi ngược chiều”. Ng...\n",
      "\n",
      "  Rank 3 (Score: 0.8407)\n",
      "  Record ID: QCVN 41:2024/BGTVT#M.1\n",
      "  Text: M.1  Nhóm biển báo cấm\n",
      "Biển số P.101: Đường cấm\n",
      "\n",
      "\n",
      "Biển số P.102: Cấm đi ngược chiều\n",
      "\n",
      "\n",
      "Biển số P.103a: Cấm xe ôtô\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "| Loại đường   |   Đường cao tốc |   Đường đôi ngoài đô thị |   Đường thông thường ...\n",
      "\n",
      "----------------------------------------\n",
      "Test ID: public_test_54\n",
      "Question: \"Biển có viền đỏ, nền trắng, hình vẽ màu đen trong hình bên là biển báo cấm rẽ phải\". Đúng hay sai?\n",
      "High-confidence documents found: 5\n",
      "\n",
      "  Rank 1 (Score: 0.9683)\n",
      "  Record ID: QCVN 41:2024/BGTVT#22\n",
      "  Text: Ý nghĩa sử dụng các biển báo cấm\n",
      "22.1.   tên các biển như sau:\n",
      "- Biển số P.101: Đường cấm;\n",
      "- Biển số P.102: Cấm đi ngược chiều;\n",
      "- Biển số P.103a: Cấm xe ô tô;\n",
      "- Biển số P.103(b,c): Cấm xe ô tô rẽ trái...\n",
      "\n",
      "  Rank 2 (Score: 0.8736)\n",
      "  Record ID: QCVN 41:2024/BGTVT#32\n",
      "  Text: Ý nghĩa sử dụng các biển hiệu lệnh\n",
      "32.1. Biển hiệu lệnh có mã R và R.E với tên các biển như sau:\n",
      "- Biển số R.122: Dừng lại;\n",
      "- Biển số R.301(a,b,c,d,e,f,g,h): Hướng đi phải theo;\n",
      "- Biển số R.302(a,b,c)...\n",
      "\n",
      "  Rank 3 (Score: 0.8202)\n",
      "  Record ID: QCVN 41:2024/BGTVT#M.1\n",
      "  Text: M.1  Nhóm biển báo cấm\n",
      "Biển số P.101: Đường cấm\n",
      "\n",
      "\n",
      "Biển số P.102: Cấm đi ngược chiều\n",
      "\n",
      "\n",
      "Biển số P.103a: Cấm xe ôtô\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "| Loại đường   |   Đường cao tốc |   Đường đôi ngoài đô thị |   Đường thông thường ...\n",
      "\n",
      "----------------------------------------\n",
      "Test ID: public_test_55\n",
      "Question: Hướng đi đến Thành phố Vinh là hướng đi thẳng, đúng hay sai?\n",
      "High-confidence documents found: 2\n",
      "\n",
      "  Rank 1 (Score: 0.8684)\n",
      "  Record ID: QCVN 41:2024/BGTVT#36\n",
      "  Text: Ý nghĩa sử dụng các biển chỉ dẫn\n",
      "36.1. Biển chỉ dẫn trên các đường ô tô không phải là đường cao tốc có mã “I” với tên các biển như sau:\n",
      "- Biển số I.401: Bắt đầu đường ưu tiên;\n",
      "- Biển số I.402: Hết đoạ...\n",
      "\n",
      "  Rank 2 (Score: 0.8061)\n",
      "  Record ID: QCVN 41:2024/BGTVT#32\n",
      "  Text: Ý nghĩa sử dụng các biển hiệu lệnh\n",
      "32.1. Biển hiệu lệnh có mã R và R.E với tên các biển như sau:\n",
      "- Biển số R.122: Dừng lại;\n",
      "- Biển số R.301(a,b,c,d,e,f,g,h): Hướng đi phải theo;\n",
      "- Biển số R.302(a,b,c)...\n",
      "\n",
      "============================================================\n",
      "CASES WITHOUT HIGH-CONFIDENCE RESULTS\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T15:48:01.561463Z",
     "start_time": "2025-07-30T15:48:01.544360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save filtered results\n",
    "filtered_results_path = \"../../results/filtered_public_test_task1_results.json\"\n",
    "os.makedirs(os.path.dirname(filtered_results_path), exist_ok=True)\n",
    "\n",
    "# Add metadata to the saved results\n",
    "filtered_results_with_metadata = {\n",
    "    \"metadata\": {\n",
    "        \"similarity_threshold\": similarity_threshold,\n",
    "        \"total_test_cases\": len(filtered_test_results),\n",
    "        \"cases_with_high_confidence_results\": len(high_confidence_cases),\n",
    "        \"cases_without_high_confidence_results\": len(no_confidence_cases),\n",
    "        \"filtering_retention_rate\": filtering_analysis[\"retention_rate\"],\n",
    "        \"average_high_confidence_score\": filtering_analysis[\"avg_high_confidence_score\"]\n",
    "    },\n",
    "    \"results\": filtered_test_results\n",
    "}\n",
    "\n",
    "with open(filtered_results_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(filtered_results_with_metadata, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nFiltered results saved to: {filtered_results_path}\")\n",
    "\n"
   ],
   "id": "55314612384ce214",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered results saved to: ../../results/filtered_public_test_task1_results.json\n"
     ]
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create a summary report",
   "id": "d4a5f662108980f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T15:48:41.620053Z",
     "start_time": "2025-07-30T15:48:41.614524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_summary_report(filtered_results, threshold):\n",
    "    \"\"\"Create a detailed summary report of filtering results\"\"\"\n",
    "\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(\"DETAILED SUMMARY REPORT\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    # Distribution of filtered document counts\n",
    "    count_distribution = {}\n",
    "    for result in filtered_results:\n",
    "        count = result['filtered_count']\n",
    "        count_distribution[count] = count_distribution.get(count, 0) + 1\n",
    "\n",
    "    print(f\"\\nDistribution of high-confidence documents per test case:\")\n",
    "    for count in sorted(count_distribution.keys()):\n",
    "        cases = count_distribution[count]\n",
    "        percentage = cases / len(filtered_results) * 100\n",
    "        print(f\"  {count} documents: {cases} cases ({percentage:.1f}%)\")\n",
    "\n",
    "    # Score distribution for high-confidence results\n",
    "    all_scores = []\n",
    "    for result in filtered_results:\n",
    "        for doc in result['top_results']:\n",
    "            all_scores.append(doc['score'])\n",
    "\n",
    "    if all_scores:\n",
    "        score_ranges = {\n",
    "            f\"{threshold:.1f}-0.85\": sum(1 for s in all_scores if threshold < s <= 0.85),\n",
    "            \"0.85-0.90\": sum(1 for s in all_scores if 0.85 < s <= 0.90),\n",
    "            \"0.90-0.95\": sum(1 for s in all_scores if 0.90 < s <= 0.95),\n",
    "            \"0.95-1.00\": sum(1 for s in all_scores if 0.95 < s <= 1.00)\n",
    "        }\n",
    "\n",
    "        print(f\"\\nScore distribution of high-confidence results:\")\n",
    "        for range_name, count in score_ranges.items():\n",
    "            percentage = count / len(all_scores) * 100 if all_scores else 0\n",
    "            print(f\"  {range_name}: {count} documents ({percentage:.1f}%)\")\n",
    "\n",
    "\n",
    "create_summary_report(filtered_test_results, similarity_threshold)\n"
   ],
   "id": "f3972e83d9ce172b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DETAILED SUMMARY REPORT\n",
      "============================================================\n",
      "\n",
      "Distribution of high-confidence documents per test case:\n",
      "  1 documents: 1 cases (2.0%)\n",
      "  2 documents: 6 cases (12.0%)\n",
      "  3 documents: 4 cases (8.0%)\n",
      "  4 documents: 2 cases (4.0%)\n",
      "  5 documents: 37 cases (74.0%)\n",
      "\n",
      "Score distribution of high-confidence results:\n",
      "  0.8-0.85: 135 documents (61.9%)\n",
      "  0.85-0.90: 38 documents (17.4%)\n",
      "  0.90-0.95: 17 documents (7.8%)\n",
      "  0.95-1.00: 28 documents (12.8%)\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Optional: Adjust threshold and compare results",
   "id": "b2888430f312721f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T15:49:12.799442Z",
     "start_time": "2025-07-30T15:49:12.787355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"THRESHOLD COMPARISON\")\n",
    "print(f\"{'=' * 60}\")\n",
    "\n",
    "thresholds_to_test = [0.7, 0.75, 0.8, 0.85, 0.9]\n",
    "threshold_comparison = {}\n",
    "\n",
    "for thresh in thresholds_to_test:\n",
    "    filtered_at_thresh = filter_results_by_threshold(test_results, thresh)\n",
    "    cases_with_results = sum(1 for r in filtered_at_thresh if len(r['top_results']) > 0)\n",
    "    total_docs = sum(r['filtered_count'] for r in filtered_at_thresh)\n",
    "\n",
    "    threshold_comparison[thresh] = {\n",
    "        'cases_with_results': cases_with_results,\n",
    "        'total_documents': total_docs,\n",
    "        'coverage_rate': cases_with_results / len(filtered_at_thresh) * 100\n",
    "    }\n",
    "\n",
    "print(f\"{'Threshold':<10} {'Cases w/ Results':<15} {'Total Docs':<12} {'Coverage Rate':<12}\")\n",
    "print(f\"{'-' * 50}\")\n",
    "for thresh, stats in threshold_comparison.items():\n",
    "    print(\n",
    "        f\"{thresh:<10.2f} {stats['cases_with_results']:<15} {stats['total_documents']:<12} {stats['coverage_rate']:<12.1f}%\")"
   ],
   "id": "2322b4522b556938",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "THRESHOLD COMPARISON\n",
      "============================================================\n",
      "Threshold  Cases w/ Results Total Docs   Coverage Rate\n",
      "--------------------------------------------------\n",
      "0.70       50              250          100.0       %\n",
      "0.75       50              243          100.0       %\n",
      "0.80       50              218          100.0       %\n",
      "0.85       48              83           96.0        %\n",
      "0.90       40              45           80.0        %\n"
     ]
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6d360ddb96178176"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
