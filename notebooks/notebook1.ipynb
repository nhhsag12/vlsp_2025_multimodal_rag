{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-22T11:06:36.742897Z",
     "start_time": "2025-07-22T11:06:36.727497Z"
    }
   },
   "source": [
    "import json\n",
    "\n",
    "\n",
    "data_path = \"../data/VLSP 2025 - MLQA-TSR Data Release/train_data/vlsp_2025_train.json\"\n",
    "with open(data_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(data[0:10])\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 'train_1', 'image_id': 'train_1_3', 'question': 'Biển báo cấm xe khách trên 29 chỗ được áp dụng trong các khoảng thời gian nào? ', 'relevant_articles': [{'law_id': 'QCVN 41:2024/BGTVT', 'article_id': '22'}], 'question_type': 'Multiple choice', 'choices': {'A': 'Từ 6:30 đến 8:00 và từ 16:30 đến 18:30; ngoài các khoảng thời gian này không được phép lưu thông.', 'B': 'Từ 6:30 đến 8:00 và từ 16:30 đến 18:30; ngoài các khoảng thời gian này được phép lưu thông.', 'C': 'Cấm lưu thông cả ngày.', 'D': 'D. Không cấm xe khách trên 29 chỗ lưu thông.'}, 'answer': 'B'}, {'id': 'train_2', 'image_id': 'train_1_3', 'question': 'Những loại phương tiện nào bị cấm trên đoạn đường này', 'relevant_articles': [{'law_id': 'QCVN 41:2024/BGTVT', 'article_id': '26'}, {'law_id': 'QCVN 41:2024/BGTVT', 'article_id': '14'}], 'question_type': 'Multiple choice', 'choices': {'A': 'Xe khách trên 29 chỗ', 'B': 'ô tô con', 'C': 'Xe máy', 'D': 'Xe đạp'}, 'answer': 'A'}, {'id': 'train_3', 'image_id': 'train_1_3', 'question': 'Thời gian cấm xe khách trên 29 chỗ có bị thay đổi theo mùa không?', 'relevant_articles': [{'law_id': 'QCVN 41:2024/BGTVT', 'article_id': '26'}], 'question_type': 'Multiple choice', 'choices': {'A': 'Thời gian cấm xe khách thay đổi vào mùa hè và mùa đông', 'B': 'Thời gian cấm xe khách thay đổi vào các ngày lễ, Tết', 'C': 'Thời gian cấm xe khách cố định, không thay đổi theo mùa', 'D': 'Thời gian cấm xe khách chỉ áp dụng vào giờ cao điểm buổi sáng'}, 'answer': 'C'}, {'id': 'train_4', 'image_id': 'train_1_20', 'question': 'Biển báo cấm dừng xe và đỗ xe kèm theo biển phụ ghi khoảng cách 300m có ý nghĩa gì? Việc cấm dừng và đỗ xe này áp dụng trong phạm vi nào và có được phép dừng hoặc đỗ xe ngoài phạm vi này không?', 'relevant_articles': [{'law_id': 'QCVN 41:2024/BGTVT', 'article_id': '26'}], 'question_type': 'Multiple choice', 'choices': {'A': 'A. Cấm dừng và đỗ xe trong phạm vi 300m theo hướng biển báo, không được phép dừng hoặc đỗ xe trong phạm vi này.', 'B': 'B. Cấm dừng xe nhưng được phép đỗ xe trong phạm vi 300m.', 'C': 'C. Cấm đỗ xe nhưng được phép dừng xe trong phạm vi 300m.', 'D': 'D. Biển chỉ mang tính chất cảnh báo, không bắt buộc cấm dừng hoặc đỗ xe trong phạm vi 300m.'}, 'answer': 'A'}, {'id': 'train_5', 'image_id': 'train_1_10', 'question': 'Biển hiệu lệnh hình tròn này có ý nghĩa và hiệu lực áp dụng thế nào? ', 'relevant_articles': [{'law_id': 'QCVN 41:2024/BGTVT', 'article_id': '32'}, {'law_id': 'QCVN 41:2024/BGTVT', 'article_id': '7'}], 'question_type': 'Multiple choice', 'choices': {'A': 'A. Biển bắt buộc tất cả các phương tiện phải rẽ phải theo hướng chỉ dẫn, không có ngoại lệ.', 'B': 'B. Biển bắt buộc các phương tiện rẽ phải, trừ các xe ưu tiên khi làm nhiệm vụ khẩn cấp.', 'C': 'C. Biển chỉ mang tính chất khuyến cáo, các phương tiện có thể chọn rẽ hoặc đi thẳng.', 'D': 'D. Biển áp dụng cho tất cả phương tiện, trừ xe đạp và người đi bộ.'}, 'answer': 'B'}, {'id': 'train_6', 'image_id': 'train_1_18', 'question': 'Biển báo tam giác báo hiệu điều gì? Theo quy định hiện hành, người tham gia giao thông cần lưu ý những gì khi gặp biển báo này?', 'relevant_articles': [{'law_id': 'QCVN 41:2024/BGTVT', 'article_id': '28'}], 'question_type': 'Multiple choice', 'choices': {'A': 'Báo hiệu trước đoạn đường có phà qua sông; người tham gia giao thông phải chú ý giảm tốc độ và sẵn sàng dừng lại nếu cần.', 'B': 'Cấm tất cả các loại phương tiện qua phà; phải tìm đường khác.', 'C': 'Chỉ áp dụng cho xe ô tô; các loại xe khác không bị ảnh hưởng.', 'D': 'Báo hiệu khu vực có bến phà phục vụ riêng cho người đi bộ.'}, 'answer': 'A'}, {'id': 'train_7', 'image_id': 'train_1_18', 'question': 'Biển báo nguy hiểm hình chiếc ô tô trên phà có ý nghĩa cảnh báo gì về an toàn giao thông? Theo quy chuẩn hiện hành, hành vi nào bị cấm hoặc hạn chế khi lưu thông qua khu vực này?', 'relevant_articles': [{'law_id': 'QCVN 41:2024/BGTVT', 'article_id': '28'}, {'law_id': 'QCVN 41:2024/BGTVT', 'article_id': '30'}], 'question_type': 'Multiple choice', 'choices': {'A': 'Cảnh báo đoạn đường có bến phà, cấm dừng và đỗ xe trên đoạn đường dẫn vào bến phà để đảm bảo lưu thông an toàn.', 'B': 'Cảnh báo bến phà, nhưng không có giới hạn nào về dừng hoặc đỗ xe.', 'C': 'Cấm tất cả các phương tiện giao thông qua phà.', 'D': 'Chỉ cảnh báo cho xe tải, không áp dụng cho xe con và xe máy.'}, 'answer': 'A'}, {'id': 'train_8', 'image_id': 'train_1_18', 'question': 'Biển báo nguy hiểm hình chiếc ô tô trên phà báo hiệu đoạn đường có bến phà, và yêu cầu người tham gia giao thông giảm tốc độ, chú ý quan sát.\\nĐúng hay sai?', 'relevant_articles': [{'law_id': 'QCVN 41:2024/BGTVT', 'article_id': '28'}, {'law_id': 'QCVN 41:2024/BGTVT', 'article_id': '30'}], 'question_type': 'Yes/No', 'answer': 'Đúng'}, {'id': 'train_9', 'image_id': 'train_1_12', 'question': 'Biển báo phía trên báo hiệu rằng người tham gia giao thông có thể tiếp tục đi thẳng hoặc rẽ trái tại vị trí này.\\nĐúng hay sai?', 'relevant_articles': [{'law_id': 'QCVN 41:2024/BGTVT', 'article_id': '32'}], 'question_type': 'Yes/No', 'answer': 'Đúng'}, {'id': 'train_10', 'image_id': 'train_1_12', 'question': 'Biển báo có hình mũi tên chỉ thẳng và rẽ trái đồng thời cho phép người tham gia giao thông rẽ phải nếu không có biển báo khác.\\nĐúng hay sai?', 'relevant_articles': [{'law_id': 'QCVN 41:2024/BGTVT', 'article_id': '32'}], 'question_type': 'Yes/No', 'answer': 'Sai'}]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T13:24:40.143720Z",
     "start_time": "2025-07-16T13:24:40.140740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for record in data:\n",
    "    if record[\"question_type\"] == \"Yes/No\":\n",
    "        answer = record.pop(\"answer\")\n",
    "        record[\"choices\"] = None\n",
    "        record[\"answer\"] = answer\n",
    "    file_name = f\"{record[\"image_id\"]}.jpg\"\n",
    "    record[\"file_name\"] = file_name"
   ],
   "id": "edd87bd696cbe4ee",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T13:24:40.194539Z",
     "start_time": "2025-07-16T13:24:40.191283Z"
    }
   },
   "cell_type": "code",
   "source": "print(data[0].keys())",
   "id": "47e8fd15ee1a629a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['id', 'image_id', 'question', 'relevant_articles', 'question_type', 'choices', 'answer', 'file_name'])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T13:24:40.256068Z",
     "start_time": "2025-07-16T13:24:40.242145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import csv\n",
    "df = open(\"../data/metadata.csv\", \"w\")\n",
    "writer = csv.writer(df)\n",
    "for idx, data_row in enumerate(data):\n",
    "    if idx==0:\n",
    "        header = data_row.keys()\n",
    "        writer.writerow(header)\n",
    "    writer.writerow(data_row.values())\n",
    "df.close()"
   ],
   "id": "da93efc9432a237c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T13:24:42.431894Z",
     "start_time": "2025-07-16T13:24:40.294726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=\"../data/VLSP 2025 - MLQA-TSR Data Release/train_data/train_images\")"
   ],
   "id": "80587b2972cfa610",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nhhsag12/Documents/Multimodal Machine Learning/VLSP_2025/vlsp_2025_multimodal_rag/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading data: 100%|██████████| 305/305 [00:00<00:00, 21730.30files/s]\n",
      "Generating train split: 530 examples [00:00, 5354.22 examples/s]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T13:24:52.030263Z",
     "start_time": "2025-07-16T13:24:52.019603Z"
    }
   },
   "cell_type": "code",
   "source": "dataset",
   "id": "4e721abd80f154a1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'image_id', 'question', 'relevant_articles', 'question_type', 'choices', 'answer', 'image'],\n",
       "        num_rows: 530\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T13:25:40.395342Z",
     "start_time": "2025-07-16T13:25:28.316138Z"
    }
   },
   "cell_type": "code",
   "source": "dataset.push_to_hub(\"nhhsag12/vlsp_2025_multimodal_rag\", private=True)\n",
   "id": "e97b086c446d424f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]\n",
      "Map:   0%|          | 0/530 [00:00<?, ? examples/s]\u001B[A\n",
      "Map:  19%|█▉        | 100/530 [00:00<00:00, 655.84 examples/s]\u001B[A\n",
      "Map:  38%|███▊      | 200/530 [00:00<00:00, 650.45 examples/s]\u001B[A\n",
      "Map:  57%|█████▋    | 300/530 [00:00<00:00, 693.79 examples/s]\u001B[A\n",
      "Map:  75%|███████▌  | 400/530 [00:00<00:00, 746.99 examples/s]\u001B[A\n",
      "Map: 100%|██████████| 530/530 [00:00<00:00, 635.82 examples/s]\u001B[A\n",
      "\n",
      "Creating parquet from Arrow format:   0%|          | 0/6 [00:00<?, ?ba/s]\u001B[A\n",
      "Creating parquet from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 29.29ba/s]\u001B[A\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:10<00:00, 10.25s/ shards]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/nhhsag12/vlsp_2025_multimodal_rag/commit/65c7f4966ad691ff792709005c8caa1ec4bab7c2', commit_message='Upload dataset', commit_description='', oid='65c7f4966ad691ff792709005c8caa1ec4bab7c2', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/nhhsag12/vlsp_2025_multimodal_rag', endpoint='https://huggingface.co', repo_type='dataset', repo_id='nhhsag12/vlsp_2025_multimodal_rag'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T16:46:14.539224Z",
     "start_time": "2025-08-16T16:45:01.374962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from src.reranker.cross_encoder import CrossEncoder\n",
    "from src.multimodal_retriever.retriever_v2 import RetrieverV2\n",
    "\n",
    "reranker = RetrieverV2(pretrained_model_path=\"../src/multimodal_retriever/pretrained_model/Visualized_m3.pth\").to(\"cpu\")\n"
   ],
   "id": "10d0b0aa0587137b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nhhsag12/Documents/Multimodal Machine Learning/VLSP_2025/vlsp_2025_multimodal_rag/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/nhhsag12/Documents/Multimodal Machine Learning/VLSP_2025/vlsp_2025_multimodal_rag/.venv/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T16:46:35.870951Z",
     "start_time": "2025-08-16T16:46:35.590468Z"
    }
   },
   "cell_type": "code",
   "source": "print(reranker.device)",
   "id": "db16a55e32686d6a",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RetrieverV2' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[43mreranker\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdevice\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Multimodal Machine Learning/VLSP_2025/vlsp_2025_multimodal_rag/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1962\u001B[39m, in \u001B[36mModule.__getattr__\u001B[39m\u001B[34m(self, name)\u001B[39m\n\u001B[32m   1960\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[32m   1961\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[32m-> \u001B[39m\u001B[32m1962\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[32m   1963\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m).\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m object has no attribute \u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1964\u001B[39m )\n",
      "\u001B[31mAttributeError\u001B[39m: 'RetrieverV2' object has no attribute 'device'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T16:47:23.642071Z",
     "start_time": "2025-08-16T16:47:23.562348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_path_1 = \"../data/VLSP 2025 - MLQA-TSR Data Release/public_test/public_test_images/public_test_images/public_test_2_1.jpg\"\n",
    "image_path_2 = \"../data/VLSP 2025 - MLQA-TSR Data Release/public_test/public_test_images/public_test_images/public_test_2_2.jpg\"\n",
    "image_1 = Image.open(image_path_1)\n",
    "image_2 = Image.open(image_path_1)\n",
    "preprocessed_images = reranker.preprocess_train(image_1)\n",
    "preprocessed_images"
   ],
   "id": "3717b22452d4f554",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.4273, -1.3981, -1.3981,  ..., -1.6025, -1.2521, -1.5003],\n",
       "         [-1.3835, -1.3689, -1.3981,  ..., -1.2959, -1.3251, -1.5587],\n",
       "         [-1.4273, -1.3835, -1.3981,  ..., -1.4127, -1.4273, -1.5879],\n",
       "         ...,\n",
       "         [ 0.4413,  0.4121,  0.4705,  ...,  0.7041,  0.6749,  0.6749],\n",
       "         [ 0.3829,  0.4121,  0.5289,  ...,  0.6603,  0.7333,  0.7333],\n",
       "         [ 0.5435,  0.4413,  0.5435,  ...,  0.5873,  0.5435,  0.7041]],\n",
       "\n",
       "        [[-1.4219, -1.3919, -1.3919,  ..., -1.5720, -1.2418, -1.4219],\n",
       "         [-1.3769, -1.3619, -1.3919,  ..., -1.2869, -1.3169, -1.4820],\n",
       "         [-1.4219, -1.3769, -1.3919,  ..., -1.4519, -1.4069, -1.5270],\n",
       "         ...,\n",
       "         [ 0.4841,  0.4691,  0.5291,  ...,  0.6942,  0.6642,  0.6642],\n",
       "         [ 0.4240,  0.4691,  0.5891,  ...,  0.6491,  0.7242,  0.7242],\n",
       "         [ 0.5891,  0.4991,  0.6041,  ...,  0.5741,  0.5291,  0.6942]],\n",
       "\n",
       "        [[-1.2385, -1.2100, -1.2100,  ..., -1.3380, -1.1247, -1.3238],\n",
       "         [-1.2100, -1.1816, -1.2100,  ..., -1.1105, -1.1958, -1.3665],\n",
       "         [-1.2669, -1.2100, -1.2100,  ..., -1.2811, -1.2811, -1.3807],\n",
       "         ...,\n",
       "         [ 0.4253,  0.4253,  0.4679,  ...,  0.5390,  0.5106,  0.5106],\n",
       "         [ 0.3684,  0.4253,  0.5248,  ...,  0.4964,  0.5675,  0.5675],\n",
       "         [ 0.5248,  0.4537,  0.5390,  ...,  0.4253,  0.3826,  0.5390]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T14:29:21.319969Z",
     "start_time": "2025-08-07T14:29:21.232512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_path_1 = \"../data/VLSP 2025 - MLQA-TSR Data Release/public_test/public_test_images/public_test_images/public_test_2_1.jpg\"\n",
    "image_path_2 = \"../data/VLSP 2025 - MLQA-TSR Data Release/public_test/public_test_images/public_test_images/public_test_2_2.jpg\"\n",
    "image_1 = Image.open(image_path_1)\n",
    "image_2 = Image.open(image_path_1)\n",
    "processed_image_1 = reranker.preprocess(image_1).unsqueeze(0)\n",
    "processed_image_2 = reranker.preprocess(image_2).unsqueeze(0)\n",
    "print(processed_image_1.shape)\n",
    "processed_images = torch.cat([processed_image_1, processed_image_2], dim=0)\n",
    "print(processed_images)\n",
    "print(processed_images.shape)\n",
    "\n",
    "image_embedding = reranker.encode_image(processed_images)\n",
    "print(image_embedding)\n",
    "print(image_embedding.shape)"
   ],
   "id": "8f065db3ad21e463",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n",
      "tensor([[[[-0.9310, -0.9164, -0.7996,  ..., -1.5295, -0.6974, -1.4565],\n",
      "          [-0.9018, -0.9310, -0.7850,  ..., -1.5879, -1.5149, -1.5587],\n",
      "          [-0.7996, -0.8434, -0.8288,  ..., -1.6171, -1.6901, -0.8580],\n",
      "          ...,\n",
      "          [ 0.4997,  0.5143,  0.5435,  ...,  0.8063,  0.6019,  0.5581],\n",
      "          [ 0.5581,  0.5727,  0.5435,  ...,  0.7479,  0.6895,  0.6311],\n",
      "          [ 0.4997,  0.4851,  0.4851,  ...,  0.5873,  0.6165,  0.7187]],\n",
      "\n",
      "         [[-0.8366, -0.8366, -0.7166,  ..., -1.4369, -0.5965, -1.3769],\n",
      "          [-0.8066, -0.8516, -0.7016,  ..., -1.5120, -1.4369, -1.4820],\n",
      "          [-0.6715, -0.7466, -0.7466,  ..., -1.5270, -1.6170, -0.7466],\n",
      "          ...,\n",
      "          [ 0.5591,  0.5741,  0.6041,  ...,  0.8442,  0.6491,  0.6041],\n",
      "          [ 0.6191,  0.6341,  0.6041,  ...,  0.7542,  0.6942,  0.6341],\n",
      "          [ 0.5591,  0.5441,  0.5441,  ...,  0.5741,  0.6191,  0.7242]],\n",
      "\n",
      "         [[-0.7692, -0.7408, -0.6128,  ..., -1.2243, -0.4279, -1.1532],\n",
      "          [-0.6981, -0.7408, -0.5986,  ..., -1.2954, -1.2243, -1.2669],\n",
      "          [-0.5559, -0.6270, -0.6128,  ..., -1.3096, -1.3949, -0.5844],\n",
      "          ...,\n",
      "          [ 0.4679,  0.4821,  0.5106,  ...,  0.7097,  0.5248,  0.4821],\n",
      "          [ 0.5248,  0.5390,  0.5106,  ...,  0.6386,  0.5817,  0.5248],\n",
      "          [ 0.4679,  0.4537,  0.4537,  ...,  0.4537,  0.4964,  0.6101]]],\n",
      "\n",
      "\n",
      "        [[[-0.9310, -0.9164, -0.7996,  ..., -1.5295, -0.6974, -1.4565],\n",
      "          [-0.9018, -0.9310, -0.7850,  ..., -1.5879, -1.5149, -1.5587],\n",
      "          [-0.7996, -0.8434, -0.8288,  ..., -1.6171, -1.6901, -0.8580],\n",
      "          ...,\n",
      "          [ 0.4997,  0.5143,  0.5435,  ...,  0.8063,  0.6019,  0.5581],\n",
      "          [ 0.5581,  0.5727,  0.5435,  ...,  0.7479,  0.6895,  0.6311],\n",
      "          [ 0.4997,  0.4851,  0.4851,  ...,  0.5873,  0.6165,  0.7187]],\n",
      "\n",
      "         [[-0.8366, -0.8366, -0.7166,  ..., -1.4369, -0.5965, -1.3769],\n",
      "          [-0.8066, -0.8516, -0.7016,  ..., -1.5120, -1.4369, -1.4820],\n",
      "          [-0.6715, -0.7466, -0.7466,  ..., -1.5270, -1.6170, -0.7466],\n",
      "          ...,\n",
      "          [ 0.5591,  0.5741,  0.6041,  ...,  0.8442,  0.6491,  0.6041],\n",
      "          [ 0.6191,  0.6341,  0.6041,  ...,  0.7542,  0.6942,  0.6341],\n",
      "          [ 0.5591,  0.5441,  0.5441,  ...,  0.5741,  0.6191,  0.7242]],\n",
      "\n",
      "         [[-0.7692, -0.7408, -0.6128,  ..., -1.2243, -0.4279, -1.1532],\n",
      "          [-0.6981, -0.7408, -0.5986,  ..., -1.2954, -1.2243, -1.2669],\n",
      "          [-0.5559, -0.6270, -0.6128,  ..., -1.3096, -1.3949, -0.5844],\n",
      "          ...,\n",
      "          [ 0.4679,  0.4821,  0.5106,  ...,  0.7097,  0.5248,  0.4821],\n",
      "          [ 0.5248,  0.5390,  0.5106,  ...,  0.6386,  0.5817,  0.5248],\n",
      "          [ 0.4679,  0.4537,  0.4537,  ...,  0.4537,  0.4964,  0.6101]]]])\n",
      "torch.Size([2, 3, 224, 224])\n",
      "tensor([[-0.0373, -0.0090, -0.0077,  ..., -0.0205,  0.0043, -0.0237],\n",
      "        [-0.0270, -0.0146, -0.0117,  ..., -0.0376,  0.0031, -0.0260]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([2, 1024])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T14:29:23.400868Z",
     "start_time": "2025-08-07T14:29:23.359963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_1 = \"Xin chào tôi tên là Nguyễn Huy Hoàng\"\n",
    "text_2 = \"Xin chào tôi ến từ Việt Nam\"\n",
    "text_embedding_1 = reranker.encode_text(text_1)\n",
    "print(text_embedding_1.shape)\n",
    "print(text_embedding_1)"
   ],
   "id": "69b2d4cc09f92ac2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024])\n",
      "tensor([[-0.0285,  0.0262, -0.0354,  ...,  0.0166, -0.0540,  0.0173]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T14:29:24.216399Z",
     "start_time": "2025-08-07T14:29:24.155170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_1 = \"Xin chào tôi tên là Nguyễn Huy Hoàng\"\n",
    "text_2 = \"Xin chào tôi ến từ Việt Nam\"\n",
    "texts = [text_1, text_2]\n",
    "text_embedding_1 = reranker.encode_text(text_1)\n",
    "text_embeddings = reranker.encode_text(texts)\n",
    "# text_embeddings = torch.cat([text_embedding_1, text_embedding_2], dim=0)\n",
    "print(text_embeddings.shape)\n",
    "print(text_embeddings)"
   ],
   "id": "a47155cd6c597cce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024])\n",
      "tensor([[-0.0081,  0.0150, -0.0645,  ...,  0.0069, -0.0360,  0.0149],\n",
      "        [-0.0243,  0.0007, -0.0634,  ..., -0.0040, -0.0588, -0.0341]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T14:29:26.847864Z",
     "start_time": "2025-08-07T14:29:26.842013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_texts = [text_1, text_2]\n",
    "doc_texts = [\"Nguyễn Huy Hoàng là một cái tên phổ biến ở Việt Nam\", \"Việt Nam là một đất nước xinh đẹp và có bề dày lịch sử\"]\n",
    "query_images = processed_images.to(reranker.device)"
   ],
   "id": "233f051fd87e4c34",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T14:29:33.899836Z",
     "start_time": "2025-08-07T14:29:33.804116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "relevant_score = reranker(query_texts, query_images)\n",
    "print(relevant_score)"
   ],
   "id": "d05563a9dbf1775e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1144, -1.4418, -0.3835,  ...,  0.1487, -0.1129,  1.4252],\n",
      "        [-0.1711, -1.4158, -0.4482,  ..., -0.0931, -0.4035,  1.1276]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T14:29:37.089884Z",
     "start_time": "2025-08-07T14:29:37.083965Z"
    }
   },
   "cell_type": "code",
   "source": "print(relevant_score.shape)",
   "id": "f4f4b28205e9c863",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024])\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T14:29:42.613066Z",
     "start_time": "2025-08-07T14:29:42.539256Z"
    }
   },
   "cell_type": "code",
   "source": "mm_embeddings = reranker.encode_mm(query_texts, query_images)",
   "id": "25ab666e0cf66673",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T14:29:43.694352Z",
     "start_time": "2025-08-07T14:29:43.682091Z"
    }
   },
   "cell_type": "code",
   "source": "mm_embeddings.shape",
   "id": "ab31cc9bf7c8aa2e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1024])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T13:35:52.891400Z",
     "start_time": "2025-08-07T13:35:52.885566Z"
    }
   },
   "cell_type": "code",
   "source": "torch.diagonal(relevant_score)",
   "id": "ced4495f076f7ae5",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5498, 0.4582], device='cuda:0', grad_fn=<DiagonalBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f348d0d42d123345"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
